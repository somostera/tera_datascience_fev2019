{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Anonymized credit card transactions labeled as fraudulent or genuine](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from plotting import multiple_histograms_plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exibe todas as colunas do DataFrame\n",
    "pd.options.display.max_columns = 35\n",
    "\n",
    "# deixa de utilizar a notação científica\n",
    "pd.options.display.float_format = lambda x: '%.2f' % x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima as colunas do dataframe\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante já separarmos o dataset de teste, assim garantimos que não iremos tocar nele. Até para a análise dos dados isso pode ser importante, já que nos impede de tomar decisões de feature engineering baseadas nesses dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vale frisar também que a função `train_test_split` já tem os parâmetros `shuffle` e `stratify` com valores `True` por padrão, caso contrário teríamos que setá-los explicitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qual é o tamanho dos datasets de treino e teste?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos juntar as features com o target para analisá-los em um dataframe de treino unificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima alguns exemplos do dataset\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprima os tipos de cada coluna com o método 'info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já que a maioria das features foram geradas com PCA, a correlação entre elas será baixa.\n",
    "Vamos então analisar a correlação das features com o target `Class`.\n",
    "\n",
    "Enquanto as features são contínuas, o target é binário. Para correlação entre uma variável contínua e uma binária, utilizaremos o coeficiente de correlação [Ponto Biserial](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pointbiserialr.html), que é equivalente à correlação de Pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o target é balanceado ou desbalanceado?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# será que a coluna 'Time' poderia ser convertida para 'int'?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conseguimos quebrar a coluna 'Time' em 24 bins\n",
    "# assim, cada bin representaria 2 horas cada\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos usar a função 'multiple_histograms_plot' na coluna 'Time'\n",
    "# com os bins criados acima e com hue na coluna 'Class'\n",
    "# assim poderemos tentar encontrar algum padrão de horário nos dados\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conseguimos bolar algo de feature engineering com base nos insights acima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como é a coluna 'Amount'?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temos outliers? vale a pena filtrá-los para melhor visualizar os dados?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# como é a distribuição de 'Amount'? \n",
    "# sugere alguma transformação de feature engineering?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existem alguns valores de 'Amount' muito mais recorrentes do que outros?\n",
    "# se tivesse, teria algo a ver com as fraudes?\n",
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features anonimizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# poupa-tempo :)\n",
    "\n",
    "bins_list = [\n",
    "    np.arange(-35, 10, 2.5), #v1\n",
    "    np.arange(-10, 25, 2.5), #v2\n",
    "    np.arange(-35, 10, 2.5), #v3\n",
    "    np.arange(-6, 14, 1), #v4\n",
    "    np.arange(-25, 12, 2), #v5\n",
    "    np.arange(-7.5, 8.5, 1), #v6\n",
    "    np.arange(-35, 11, 2), #v7\n",
    "    np.arange(-45, 25, 2), #v8\n",
    "    np.arange(-15, 8, 1), #v9\n",
    "    np.arange(-25, 15, 2), #v10\n",
    "    np.arange(-4, 14, 1), #v11\n",
    "    np.arange(-20, 6, 2), #v12\n",
    "    np.arange(-4, 5, 1), #v13\n",
    "    np.arange(-20, 7.5, 1.25), #v14\n",
    "    np.arange(-5, 5, 1), #v15\n",
    "    np.arange(-15, 7.5, 1.25), #v16\n",
    "    np.arange(-26, 7, 0.5), #v17\n",
    "    np.arange(-10, 4, 1), #v18\n",
    "    np.arange(-4, 6, 1), #v19\n",
    "    np.arange(-4, 8.5, 0.5), #v20\n",
    "    np.arange(-25, 30, 1), #v21\n",
    "    np.arange(-10, 10, 0.5), #v22\n",
    "    np.arange(-5, 7, 0.25), #v23\n",
    "    np.arange(-2.5, 2, 0.25), #v24\n",
    "    np.arange(-5, 2.5, 0.5), #v25\n",
    "    np.arange(-1.5, 3, 0.25), #v26\n",
    "    np.arange(-8, 4, 0.25), #v27\n",
    "    np.arange(-1.8, 2.5, 0.1), #v28\n",
    "]\n",
    "\n",
    "for var, bins in zip(range(1, len(bins_list)+1), bins_list):\n",
    "    multiple_histograms_plot(df_train, x=f'V{var}', hue='Class',\n",
    "                             bins=bins, density=True,\n",
    "                             title=f\"Distribuições de 'V{var}', \"\n",
    "                                    \"segmentadas por 'Class' e normalizadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver acima que algumas variáveis parecem ter mais poder preditivo do que outras.\n",
    "\n",
    "Vamos seguir para a modelagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline de pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de treinar o modelo e fazer predições, se tivermos criado alguma transformação de feature engineering na seção anterior, precisamos aplicar nos dados que serão usados no notebook de treinamento.\n",
    "\n",
    "Obs.: como nós fizemos os testes em `df_train`, `X_train` não foi modificado e também precisará passar pelo pré-processador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos re-criar `df_train` e `df_test` e salvá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis='columns')\n",
    "df_test = pd.concat([X_test, y_test], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../data/train.csv', index=False)\n",
    "df_test.to_csv('../data/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "100px",
    "left": "1179px",
    "top": "718px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
